# -*- coding: utf-8 -*-
"""diabetic data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nVDErVu5PVSYBtPu-4Kv0R91XgX2BnBL
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score

df = pd.read_csv('/content/diabetes.csv')

df.head()

df.shape

df.describe()

#finding diabetic and non diabetic
df['Outcome'].value_counts()

#o=> non-diabetic   1=> non-diabetic
df.groupby('Outcome').mean()

df.isnull().sum()   ##checking missing value

##cheacking the 0 values
df[df['Glucose']== 0].shape[0]

df[df['BloodPressure']== 0].shape[0]

df[df['SkinThickness']== 0].shape[0]

df[df['Insulin']== 0].shape[0]

df[df['BMI']== 0].shape[0]

##repleacing zero with mean values of that colimn
df['Glucose']= df['Glucose'].replace(0,df['Glucose'].mean())
df[df['Glucose']== 0].shape[0]

df['BloodPressure']= df['BloodPressure'].replace(0,df['BloodPressure'].mean())
df[df['BloodPressure']== 0].shape[0]

df['SkinThickness']= df['SkinThickness'].replace(0,df['SkinThickness'].mean())
df['Insulin']= df['Insulin'].replace(0,df['Insulin'].mean())
df['BMI']= df['BMI'].replace(0,df['BMI'].mean())

print(df)

X= df.drop(columns = 'Outcome', axis=1)  ##dropping a column axis=1,dropping a row axis=0
Y= df['Outcome']

##data standardization in particular range with standard scaler
scaler = StandardScaler()
new_X = scaler.fit_transform(X)    ####adjust all the values in 0 to 1

X= new_X
Y= df['Outcome']

print(X)

import seaborn as sns
import matplotlib.pyplot as plt

"""

Analysis with graphs"""

##countplot
sns.set_theme(style="whitegrid")
sns.countplot(x=df["Outcome"])
N,P = df['Outcome'].value_counts()
plt.title('Diabetic')
print('-ve(0): ',N)
print('+ve(1): ',P)
plt.show()

##pie plot
df['Outcome'].value_counts().plot.pie(autopct='%1.1f%%', explode=[0,0.1,], shadow=True, startangle=90)
plt.title('diabetic')
plt.axis('equal')
plt.show()

##Histogram of Each feature
df.hist(bins=10,figsize=(10,10))
plt.show()

##scatter plot matrix
from pandas.plotting import scatter_matrix
scatter_matrix(df, figsize = (10,10))
plt.show()

#pairplot
sns.pairplot(data = df, hue = 'Outcome')
plt.show()

"""Correlation analysis

Correlation analysis is used to quantify the degree to which two variables are related. Through the correlation analysis, you evaluate correlation coefficient that tells you how much one variable changes when the other one does. Correlation analysis provides you with a linear relationship between two variables. When we correlate feature variables with the target variable, we get to know that how much dependency is there between particular feature variables and target variable.
"""

plt.figure(figsize=(14,8))
sns.set_theme(style="white")
corr = df.corr()         ####get correlations of each features in dataset
##plot heat map,
heatmap = sns.heatmap(corr, annot=True, cmap="Blues", fmt='.1g')

"""# train-test split"""

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size= 0.2, stratify=Y, random_state=2)

!pip install catboost

from catboost import CatBoostClassifier, Pool
from sklearn.metrics import confusion_matrix
model = CatBoostClassifier(verbose=0)
model.fit(X_train, Y_train)
# Predicting the Test set results
y_pred = model.predict(X_test)

# Making the Confusion Matrix
cm = confusion_matrix(Y_test, y_pred)

# Plotting the confusion matrix
sns.heatmap(cm)
plt.show()

"""build the classification algo"""

##SUPPORT VECTOR MACHINE
classifier = svm.SVC(kernel='linear')
classifier.fit(X_train, Y_train)

#accuracy score
X_test_prediction = classifier.predict(X_test)
data_accuracy = accuracy_score(X_test_prediction, Y_test)
print('accuracy score:' , data_accuracy)

##LOGISTIC REGRESSION
from sklearn import linear_model
logr = linear_model.LogisticRegression()
logr.fit(X_train,Y_train)

X_test_prediction = logr.predict(X_test)
data_accuracy = accuracy_score(X_test_prediction, Y_test)
print('accuracy score:' , data_accuracy)

##KNN
from sklearn.neighbors import KNeighborsClassifier
neigh = KNeighborsClassifier(n_neighbors=3)
neigh.fit(X_train,Y_train)

X_test_prediction = neigh.predict(X_test)
data_accuracy = accuracy_score(X_test_prediction, Y_test)
print('accuracy score:' , data_accuracy)

# Fitting Naive Bayes to the Training set
from sklearn.naive_bayes import GaussianNB
knn = GaussianNB()
knn.fit(X_train, Y_train)

#accuracy score
X_test_prediction = knn.predict(X_test)
data_accuracy = accuracy_score(X_test_prediction, Y_test)
print('accuracy score:' , data_accuracy)

#Fitting Decision Tree classifier to the training set
from sklearn.tree import DecisionTreeClassifier
decisiontree = DecisionTreeClassifier()
decisiontree = classifier.fit(X_train,Y_train)

#accuracy score
X_test_prediction = decisiontree.predict(X_test)
data_accuracy = accuracy_score(X_test_prediction, Y_test)
print('accuracy score:' , data_accuracy)

#Random Forest
from sklearn.ensemble import RandomForestClassifier
Ranfr= RandomForestClassifier()
Ranfr.fit(X_train, Y_train)

#accuracy score
X_test_prediction = Ranfr.predict(X_test)
data_accuracy = accuracy_score(X_test_prediction, Y_test)
print('accuracy score:' , data_accuracy)

"""AS in svm we get maximum accuracy score , ill continue with svm model"""

##cheacking with input data
input_data= (4,110,92,0,0,37.6,0.191,30)
input_data_as_nparrary= np.asarray(input_data)    ##changing the input data as np array
##as the model will expect 768 value, reshapping to make the model understand that its one value
reshape = input_data_as_nparrary.reshape(1,-1)

new_input = scaler.fit_transform(reshape)

##prediction
prediction =classifier.predict(new_input)
print(prediction)

if (prediction[0] == 0):
    print ('diabetic')
else:
        print ('non diabetic')

"""I have done a full examination on a dataset related to diabetes and basic data analysis.Have detected the outliers with a function that we've coded ourselves and got rid of these outlier values for a better machine learning score and have applied 6 different machine learning algorithms on our data and found out the best one for our dataset.

saving the trained model
"""

import pickle

filename = "trained_model.sav"
pickle.dump(classifier, open(filename, 'wb'))    ##wb stands for write binary

##loading the model
load_model = pickle.load(open('trained_model.sav', 'rb'))

##cheacking with input data
input_data= (4,110,92,0,0,37.6,0.191,30)
input_data_as_nparrary= np.asarray(input_data)    ##changing the input data as np array
##as the model will expect 768 value, reshapping to make the model understand that its one value
reshape = input_data_as_nparrary.reshape(1,-1)
new_input = scaler.fit_transform(reshape)
##prediction
prediction =classifier.predict(new_input)
print(prediction)
if (prediction[0] == 0):
    print ('diabetic')
else:
        print ('non diabetic')

"""# DEPLOYING THE ML MODEL USING **STREAMLIT**

download the cell and go to spyder

import numpy as np
import pickle
import streamlit as st
#loading the saved model
loaded_model = pickle.load(open('D:/New folder/trained_model (1).sav', 'rb'))


##creating function for prediction
def diabetes_prediction(input_data):
    ##changing the input data to numpy array
    input_data_as_numpy_array = np.asarray(input_data)
    ##reshape the array as we are predicting for one instance
    input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)
    
    prediction = loaded_model.predict(input_data_reshaped)
    print(prediction)
    
    if (prediction[0] == 0):
        return 'the person is not diabetic'
    else:
        return 'the person is diabetic'
    


def main():
    
    #giving a title to the webpage
    st.title('diabetic prediction web')
    
    #getting the input data from user
    
    Pregnancies = st.text_input("Number of Pregnancies")
    Glucose = st.text_input("Glucose Level")
    BloodPressure = st.text_input("Blood Pressure value")
    Insulin = st.text_input("Insulin Level")
    BMI = st.text_input("BMI value")
    SkinThickness = st.text_input("SkinThickness value")
    DiabetesPedigreeFunction = st.text_input("Diabetes Pedigree Function Value")
    Age = st.text_input("Your age")
    
    #code for prediction
    diagnosis = ''
    
    #creation a button for prediction
    if st.button('Diabetes Test Result'):
        diagnosis = diabetes_prediction([Pregnancies, Glucose, BloodPressure, Insulin, BMI, SkinThickness, DiabetesPedigreeFunction, Age])
        
    st.success(diagnosis)
    
    
    
if __name__== '__main__':
    main()


from anaconda open terminal and run
streamlit run 'saved spyder file path'

# **DEPLOYING ML MODEL USING FASTAPI AND Ngrok **
"""

!pip install fastapi  ##for creating the api
!pip install uvicorn  ##access the server
!pip install pickle5  ##for loading the saved model
!pip install pydantic  ##to structure the format in which the data is needed
!pip install scikit-learn
!pip install requests ##for posting the url
!pip install pypi-json  ##the data will be posted on json object & need to convert it back to dict
!pip install pyngrok
!pip install nest-asyncio

from fastapi import FastAPI
from pydantic import BaseModel
import pickle
import json
import uvicorn
from pyngrok import ngrok
from fastapi.middleware.cors import CORSMiddleware  ## to avoid course error and to allow the domain to use the api
import nest_asyncio

app = FastAPI()

origins = ["*"]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class model_input(BaseModel):

    Pregnancies : int
    Glucose : int
    BloodPressure : int
    SkinThickness : int
    Insulin : int
    BMI : float
    DiabetesPedigreeFunction : float
    Age : int

# loading the saved model
diabetes_model = pickle.load(open('/content/trained_model (1).sav', 'rb')

@app.post('/diabetes_prediction')
def diabetes_predd(input_parameters : model_input):

    input_data = input_parameters.json()
    input_dictionary = json.loads(input_data)

    preg = input_dictionary['Pregnancies']
    glu = input_dictionary['Glucose']
    bp = input_dictionary['BloodPressure']
    skin = input_dictionary['SkinThickness']
    insulin = input_dictionary['Insulin']
    bmi = input_dictionary['BMI']
    dpf = input_dictionary['DiabetesPedigreeFunction']
    age = input_dictionary['Age']


    input_list = [preg, glu, bp, skin, insulin, bmi, dpf, age]

    prediction = diabetes_model.predict([input_list])

    if (prediction[0] == 0):
        return 'The person is not diabetic'
    else:
        return 'The person is diabetic'

ngrok_tunnel = ngrok.connect(8000)
print('Public URL:', ngrok_tunnel.public_url)
nest_asyncio.apply()
uvicorn.run(app, port=8000)

